
# Review : SPPNet —1st Runner Up (Object Detection), 2nd Runner Up (Image Classification) in ILSVRC 2014

>* SH Tsang의 [Review: SPPNet](https://medium.com/coinmonks/review-sppnet-1st-runner-up-object-detection-2nd-runner-up-image-classification-in-ilsvrc-906da3753679)를 번역한 글입니다.
>
>* [2014 ECCV, Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.699.8052&rep=rep1&type=pdf)

## Introduction

이번 장에는 SPPNet에 대해 알아보자. SPPNet에서는 Convolution layer와 fully connected layer에 변화를 주는 __Spatial Pyramid Pooling(SPP)__라는 새로운 기술을 소개하고 있다. 이 기술은 Microsoft에서 개발했다.

SPPNet은 ILSVRC 2014에서 1st Runner Up in Object Detection, 2nd Runner Up in Image Classification, and 5th Place in Localization Task을 달성했으며, 2014 ECCV[1] and 2015 TPAMI[2] 두 개의 논문을 발표했다.

### So why do CNNs require a fixed input size?

일반적인 CNN 구조는 크게 두 가지 layer로 구성된다. convolutional layer와 Fully connected layer이다. conv layer는 sliding-window 방식으로 feature map을 생성한다. 이 conv layer에서는 어떤 크기의 feature map도 만들 수 있기때문에 고정된 Input이 필요하지 않다(conv layer는 sliding-fliter를 사용하기 때문에 input과 output(feature map)이 대략 비슷한 종횡비(aspect ratio)를 갖는다고 볼 수 있다).

하지만, __fully-connected layer__를 통과하기 위해서는 고정된 크기(size/length)가 필요하기때문에 이 부분에서 제약이 발생한다.

<br>
<div align="center">
    <img src="http://cfile225.uf.daum.net/image/236B483758F48B351AFDBF" width="600">
    <br>
    <i>feature maps which represent the spatial arrangement of the activations</i>
</div>
<br>

논문의 저자는 기존의 CNN이 고정된 이미지 크기(e.g.,224x224)를 얻기위해 인공적인(artificial, e.g. crop or warp) 과정이 추가되었고, 이미지의 기학적인 왜곡(geometric distortion)이 발생하여 인식률을 감소시켰다고 한다. 이러한 단점을 극복하기 위해 pooling 전략을 이용한 __'spatial pyramid pooling'__ 구조를 제안하고 있다.

### Dataset

__Classification__ : 22,000개 category의 1500만개(15 millions) 이미지로 구성되어있다. ILSVRC에서는 1000개의 category만 사용하며, 각 1000개의 이미지가 있다. training/validation/testing sets(1.3M/50k/100k)로 구성되어 있다.

__Detection__ : 200개의 category, 450k/20k/40k개의 이미지

## What are covered
1. Spatial Pyramid Pooling (SPP)
2. Multi-Size Training
3. Full Image Representation
4. Multi-View Testing
5. Comparison with State-of-the-art Approaches (Classification)
6. SPPNet in Object Detection
7. Comparison with State-of-the-art Approaches (Detection)

## 1. Spatial Pyramid Pooling (SPP)

일반적인 네트워크에서는  conv layer와 FC layer 다음에 1개나 0개의 pooling layer를 사용한다. SPPNet에서는 다양한 scale을 만들기 위해 다수의 pooling layer를 제안하고 있다.

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*Af0rCJ67rVYdfIfhwnwi3A.png" width="600">
    <br>
    <i>Three-Level Spatial Pyramid Pooling (SPP) in SPPNet with Pyramid {4×4, 2×2, 1×1}.</i>
</div>
<br>

위 그림을 보면, 3-level SPP가 사용되었다. conv layer가 256개의 feature maps을 가지고 있다고하면, SPP layer에서는

>1. 먼저 각 feature map을 하나의 값이 되도록 pooling한다(회색 부분). 256-d vector가 만들어진다.
>2. 다음으로 각 feature map을 4개 값이 되도록 pooling한다(초록색 부분). 4x256-d vector가 만들어진다.
>3. 위처럼 각 feature map을 16개의 값이 되도록 pooling한다(파란 부분). 16x256-d vector가 만들어진다.
>4. 생성된 3개의 vector를 1-d vector가 되도록 연결(concatenated)한다. 
>5. 이 1-d vector을 평소처럼 FC layer에 통과시킨다.

위의 과정을 통과하기때문에 __SPPNet__에서는 AlexNet에서 했던 방법처럼 이미지의 크기를 고정시키기(fixed) 위해 자를(crop) 필요가 없다(기존의 CNN에서 고정된 이미지 사이즈가 필요한 이유는 뒷부분에 FC layer에 들어가기 위해 같은 크기여야 했기때문이다). 즉 모든 이미지 사이즈를 input으로 받을 수 있다.

## 2. Multi-Size Training

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*xE-CtZ5FXixVEO89lAT46g.png" width="600">
    <br>
    <i>SPPNet supports any sizes due to the use of SPP</i>
</div>
<br>

SPPNet에서는 다양한 크기의 input을 받을 수 있기떄문에, 네트워크의 견고함(robustness)을 다지기위해 학습시에 다양한 크기의 input을 사용할 수 있으며, overfitting을 줄일 수 있다고 한다.

그러나 실제 학습과정에서는 효율성을 위해 224x224와 180x180 이미지만 input으로 사용했으며, 180-network와 240-network는 변수(parameters)를 공유하면서 학습을 진행했다.

논문에서는 ZFNet, AlexNet, Overfeat 모델을 변형(modifications)해서 가져온(replicated) 구조를 사용한다. 

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*5wdSWu7jtBQ9jqYsIVvZAg.png" width="700">
    <br>
    <i> Replicated Model as Baseline</i>
</div>
<br>
<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*hDjV-dmgRVem_xlV4Mjq0A.png" width="500">
    <br>
    <i>Top-5 Error Rates for SPP and Multi-Size Training</i>
</div>
<br>

4-level SPPNet은 {6×6, 3×3, 2×2, 1×1} pyramid를 사용한 모델을 의미한다.

위의 그림을 보면, <strong>SSP</strong>만 적용해도 모든 모델의 성능이 향상되는 점을 볼 수 있으며,  <b>Multi-Size Training</b>를 추가하면 에러율이 더욱 감소했다(10-view는 한장의 이미지를 [four corners + 1 center]에서 자르고, 수평반전(horizontal flip)해서 augmentation한 것을 의미한다.)

## 3. Full Image Representation

SPP 구조를 사용한 CNN에는 원본(full)크기 이미지를 input으로 사용할 수 있다. 논문에서는 Full 이미지를 넣었을 때와 1장의 center crop 이미지를 이용해서 학습한 결과를 비교하고 있다. 결과를 보면 모든 모델에서 Full 이미지를 사용했을 때 성능이 향상됬다.

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*Bih63DsdU4onGCeTT5sWiA.png" width="600">
    <br>
    <i>Top-1 Error Rates for Full Image Representation</i>
</div>
<br>

## 4. Multi-View Testing

SPPNet은 Full 이미지를 바로 사용할 수 있어, __multi-view testing__을 쉽게 할 수 있다.

>1. 논문에서는 {224, 256, 300, 360, 448, 560}, 6개의 sacle로 이미지의 크기를 조정한다(resize).
>2. 각 sacle에서 {1 center, 4 corners, 4 on the middle of each side}에서 자르고, 반전(flip)을 추가해서 18개의 이미지를 만들었다. 따라서 총 96개(96 views)의 이미지를 생성한다.
>3. Full 이미지에는 반전(flip)만 해서 2개(2 views)를 만든다.

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*xE-CtZ5FXixVEO89lAT46g.png" width="600">
    <br>
    <i>SPPNet supports any sizes due to the use of SPP</i>
</div>
<br>

표를 보면, Overfeat-7로 만든 SPPNet이 9.14/9.08%의 에러율로 10% 아래의 성능을 보여준 모델임을 확인할 수 있다.

## 5. Comparison with State-of-the-art Approaches (Classification)

11개의 SPPNet을 사용해서 테스트하였으며, 결과는 예측한 값을 평균내서 사용했다. 이러한 방법을 __boosting or ensemble__라고 하며, 다른 CNN 모델(LeNet, AlexNet, ZFNet)에서도 사용한 기술이다. 

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*sO7GfqM16cJ9MyKQZpjzJw.png" width="600">
    <br>
    <i>2nd Runner Up in Image Classification (ILSVRC 2014)</i>
</div>
<br>

8.06% 에러율을 보여줬지만, 다른 deep model인 VGGNet이나 GoogLeNet보다는 성능이 좋지 않았다. 최종적으로 classification task에서 SPPNet은 3위를 달성했다.

## 6. SPPNet in Object Detection

기존 Object Detection의 강자였던 R-CNN은 2000개의 region proposals에 CNN을 통과시키기때문에 속도가 느린 단점이 있다. 하지만 SPPNet은 CNN은 한번만 통과하면되므로 R-CNN보다 빠른 속도를 보여줬다.

1. R-CNN처럼 Selective Search로 약 2000개의 region proposals를 만들어 사용한다.
2. input 이미지는 ZFNet을 사용한 SPPNet 구조을 통과하며, 한번만 수행하면 된다.
3. 마지막 conv layer에서는 region proposal로 표시된(bounded) feature map 영역이 FC layer 대신 <b>SPP layer</b>를 통과하게 된다.

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*EMhHR_g4UWEYpxsVWdpKdA.png" width= '500'>
    <br>
    <i>SPPNet for Object Detection</i>
</div>
<br>

R-CNN과 비교하면 R-CNN은 이미지 당 2000번의 conv layers를 통과하지만, SPPNet은 단 한번만 통과하면 된다. 아래 그림을 참조하자.

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*n4LE9idyGJX_efOsS-FNvw.png" width= '500'>
    <br>
    <i>R-CNN (Left) and SPPet (Right)</i>
</div>
<br>

각각의 bounding box에서 얻은 값이 FC layer를 지나고 나서, SVM이나 bounding box regressor를 지나야하기 때문에 end-to-end learning architecture라고 할 수 없다.

## 7. Comparison with State-of-the-art Approaches (Detection)

### 7.1 VOC 2007

VOC 2007에서 5 scales SPPNet은 R-CNN보다 높은 mAP(59.2%)를 기록했다. 또한 속도도 빨라진 점을 볼 수 있다.

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*IKMq2G65wrxtF55-ICDVbQ.png" width= '500'>
    <br>
    <i>VOC 2007 Results</i>
</div>
<br>
<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*9RFCDM7OUWr-f3uJRY7Ifg.png" width= '600'>
    <br>
    <i>Some Amazing Results in VOC 2017</i>
</div>
<br>

### 7.2 ILSVRC 2014

ILSVRC 2014에서 SPPNet는 35.1% maP로 2위를 달성했다.

<br>
<div align="center">
    <img src="https://cdn-images-1.medium.com/max/1000/1*6Q6hgTUudB3_DXURi891bw.png" width="400">
    <br>
    <i>SPPNet got 1st Runner-Up in ILSVRC 2014 Object Detection</i>
</div>
<br>

## References
* [2014 ECCV] [SPPNet]<br>
Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition
* [2015 TPAMI] [SPPNet]<br>
Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition
* [2014 ECCV] [ZFNet]<br>
Visualizing and Understanding Convolutional Networks
* [2012 NIPS] [AlexNet]<br>
ImageNet Classification with Deep Convolutional Neural Networks
* [2014 ICLR] [OverFeat]<br>
OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks
* [2013 IJCV] [Selective Search]<br>
Selective Search for Object Recognition
* [2014 CVPR] [R-CNN]<br>
Rich feature hierarchies for accurate object detection and semantic segmentation
